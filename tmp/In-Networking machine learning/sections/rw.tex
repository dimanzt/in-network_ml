\section{Related Work}\label{sec:rw}

% \gtodo{Giovanni}{begin rw suggestions:}The closes work in the literature to our framework is \cite{xiong2019switches}. However, they do not have per-flow model; we assess the classification results a latency analysis with more details. Also it seems that we have quite different implementation decisions.\gtodo{BRUNO}{I think it is importatnt to be sure here.}
% \gtodo{PS:}{they do have quick quality and performance evaluation at the end of section 6.3}.
% Some suggestions of categories for RW:

Recent years have seen an unprecedented surge in research combining ML and networking. For example, programmable network devices can be used to accelerate neural networks processing \cite{AIAccelerator}, to improve distributed ML through in-network aggregation \cite{DistributedML}, deployed at the edge as virtualized ML functions \cite{MLFV}, congestion control \cite{deeplearning-for-congestioncontrol} and distributed reinforcement learning \cite{Reinf-learning-in-switch}. This paper is complementary to these works, focusing on one specific aspect of ML, classification. 

In terms of traffic classification using ML, there has been a set of recent works \cite{sun2018network, pacheco2018towards, lotfollahi2020deep, dias2019innovative} \cite{xiong2019switches}. 
The closest work in the literature to our framework is \cite{xiong2019switches}. Our approach differs from all previous works, by introducing a per-flow model with fined-grained evaluation. Also, we assess the classification results presenting a latency analysis comparing per-flow and per-packet models, while in \cite{xiong2019switches} they have presented high-level experimental results. To the best of our knowledge, our contribution is a first step toward a pragmatic transformation of decision-tree models into P4 language pipeline.

% with more details. %Also it seems that we have quite different implementation

 %They explored the potential of commodity programmable switches to perform in-networking classification. For this, they mapped a trained model to match-action pipeline into the programmable data plane. However, although they demonstrated in-network classification within a programmable switch and quantified the resource requirements, they do not have a per-flow model with fined-grained evaluation. Also, comparing with them, we assess the classification results in a latency analysis with more details. Moreover, it seems that we have quite different implementation decisions.

%In this ML and networking synergy, many works arise to process ML algorithms bypassing the in-network telemetry (INT) to an external computing resource (e.g., VNF). Using this approach, we would be able to run more refined ML algorithms, by offloading to a more specialized processing unit (e.g., Graphics Processing Unit - GPU). Recently, many works have been going to this direction, such as \cite{Reinf-learning-in-switch, MLFV, DistributedML, deeplearning-for-congestioncontrol, ilievski2020efficiency}. However, differently, our work explores the primitives imposed by the Network Processing Units (NPU) to perform an initial step of forwarding decisions based on a more suitable ML algorithm for this kind of architecture. Further, from one side, this alleviates the network by avoiding unnecessary telemetry information been carried to the network, and to the other, it gives agility in the ML processing (i.e., processing in the scale of nanoseconds).

%\noindent\textbf{Network traffic classification:}this can be ML in networks in general and SDN + ML (there is something written about this below). In both cases, we are different because we are deploying ML to the data plane.

%\noindent\textbf{P4-based filtering:}\gtodo{BRUNO}{Rodolfo shared some papers with us about this.}difference to ours: they do not use any sort of ML.


%\gtodo{Giovanni}{end rw suggestions:}

%\noindent\textbf{In-network machine learning:} \bruno{added}\cite{xiong2019switches, boutaba2018comprehensive}

%Recent years have seen an unprecedented surge in research combining ML and networking. Indeed, it has been shown that network devices can be used to accelerate neural networks processing within programmable network devices \cite{AIAccelerator}, to improve distributed ML through in-network aggregation \cite{DistributedML}, deployed at the edge as virtualized ML functions \cite{MLFV}, congestion control \cite{deeplearning-for-congestioncontrol} and distributed reinforcement learning \cite{Reinf-learning-in-switch}.

%In terms of traffic classification, there has been a set of recent works \cite{sun2018network, pacheco2018towards, lotfollahi2020deep, dias2019innovative} in which the  closest work in the literature to our framework is \cite{xiong2019switches}. However, they do not have per-flow model; we assess the classification results a latency analysis with more details. Also it seems that we have quite different implementation

%This ranges from network   Also, there are works exploring the suitability of programmable network devices to accelerate the AI processing  \cite{In-net-computation, AIAccelerator}. 


%Thus, it is expected that in-network ML would gain much attention from networking community. 


%The implementation of inference within network devices is still considered challenge given that in-network computing consumes resources otherwise required for networking purposes. In this paper, we have introduced a framework for in-network classification focusing in supervised algorithms to a match-action pipeline. 
%Our prototypes are implemented both in software and hardware, and achieve full line rate classifying real world traces. To the best of our knowledge, this is the first step in implementing ML within network devices.



%\\
%\cite{berger2018towards} \bruno{trata aprendizado por refor√ßo para sistemas de cache CDN}
%\\


%The main obstacles include what data can be collected from and what control actions can be exercised on legacy network devices. 
%The ability to program the network by leveraging SDN alleviates these obstacles. The cognition from ML can be used to aid in the automation of network operation and management tasks. Therefore, it is exciting and non-trivial to apply ML techniques for such diverse and complex problems in networking. 

%ML frameworks are being accelerated using network devices [18, 44]

%\cite{sultana2019survey} \bruno{survey about IDS usnig ML and SDN}


%\noindent\textbf{Network traffic classification:}\bruno{added}\cite{sun2018network, pacheco2018towards, lotfollahi2020deep, dias2019innovative}

%\noindent\textbf{P4-based blacklisting:}

